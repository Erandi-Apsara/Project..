# AI-Driven Autonomous Robot for Disaster Area Human Detection

## ğŸ“Œ Project Overview
This project focuses on developing an intelligent autonomous robotic car 
for real-time disaster area analysis and human detection.

The system integrates:
- YOLO-based human detection
- Thermal image classification
- Audio-based human voice detection
- GPS location tracking
- Web-based monitoring dashboard

## ğŸ§  System Architecture
Camera â†’ YOLO Model  
Thermal Sensor â†’ CNN Model  
Microphone â†’ Audio Classifier  
GPS Module â†’ Location Tracking  
Web Dashboard â†’ Survivor Monitoring  

## âš™ï¸ Technologies Used
- Python
- PyTorch
- YOLOv5
- Raspberry Pi 3B+
- Flask
- Sensor Fusion

## ğŸš€ Features
- Real-time human detection
- Multi-sensor fusion
- Survivor location mapping
- Autonomous navigation capability

## ğŸ“‚ Note
Trained models and datasets are not included due to GitHub size limitations.

## ğŸ–¼ Demo

### System Architecture
![Architecture](images/circuit_1.png)

### Robot in Action
![Demo](images/prototype_1.png)
![Demo](images/project_flowchart.png)
![Demo](images/dashboard_basic_2.png)
![Demo](images/dashboard_basic_3.png)
![Demo](images/dashboard_basic_5.png)
![Demo](images/dashboard_basic_7.png)
![Demo](images/dashboard_image_3.png)
![Demo](images/test_AI.png)
![Demo](images/real.png)
![Demo](images/gas_detect1.png)
![Demo](images/gas_monitor_dashboard1.png)
![Demo](images/MFCC_1.png)
![Demo](images/confusion_matrix_for_speech1.png)
![Demo](images/sim_module_1.png)


